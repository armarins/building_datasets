{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cb9986-fcdd-4569-b3bb-80cabfe6e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, progressbar, copy, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "sys.path.insert(1, '/media/BINGODATA1/ComponentSeparation/amarins_cs/CHISEL/scripts')\n",
    "import Extension4BINGO as cs\n",
    "import copy\n",
    "sys.path.insert(1, '/media/BINGODATA1/ComponentSeparation/beam_analyzes/scripts'   )\n",
    "import beam_modelling         as model\n",
    "import handling_data          as hdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65cfbb16-0025-4990-b9ff-f74cc924ae81",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "################   GENERAL INFORMATIONS   #############\n",
    "#######################################################\n",
    "first_realization = 1\n",
    "n_realizations    = 100\n",
    "method            = \"ICA\"\n",
    "wtransform        = [\"identity\"]\n",
    "maps_wout_mean    = True\n",
    "apply_mask        = False\n",
    "add_noise         = False\n",
    "\n",
    "#######################################################\n",
    "################   WAVELETS PARAMETERS   ##############\n",
    "#######################################################\n",
    "#####\n",
    "# The main aim is to have:\n",
    "# Starlet, Axisymmetric, spin-Directional, Wavelets Standard from PyWavelets, Curvelets, Counturlets, Shearlets, Ridgelets and so on\n",
    "#####\n",
    "J     = 1  #number of scales\n",
    "use_c = True  # if you will use wavelet scale in the analysis\n",
    "\n",
    "##############\n",
    "# S2LET code\n",
    "# If you to use wtransforms by S2Let code, please, fill in the variables below:\n",
    "L        = -1 #If you write L<0, it will use L=3*nside\n",
    "J_min    = 1 \n",
    "B        = 5     \n",
    "N        = 3  # Number of directions (This is for Directional only)\n",
    "spin     = 0  # set to 0 for temperature. if non-zero, plotting routines must be changed! (This is for Directional only)\n",
    "upsample = 0  # 1 means all scales at full resolution L # 0 means multiresolution wavelet transform (This is for Directional only)\n",
    "# In the S2LET code, J scales is defined by code and not by J above.\n",
    "\n",
    "##############\n",
    "# PyWavelets\n",
    "Jpwt     = 1 #number of scales\n",
    "pywttype = \"haar\" \n",
    "\n",
    "##############\n",
    "# Needlets\n",
    "needlet   = \"mexican\" # either mexican(=gaussian), or standard\n",
    "Bneed     = 1.15            # filter is defined by function b(l/B**j), where j=freq\n",
    "p         = 0.9             # this value is only for mexican needlet\n",
    "fneed     = [15,24,30,34]   # number of freqs will be the number of scales (wavelet maps). Center of i-band will be approached given by l_center_i = B**freq_i (p=0)\n",
    "lmax_need = -1\n",
    "\n",
    "##############\n",
    "# Curvelets\n",
    "##############\n",
    "# Counturlets\n",
    "##############\n",
    "# Shearlets\n",
    "##############\n",
    "# Ridgeletssteer\n",
    "\n",
    "#######################################################\n",
    "#### COMPONENT SEPARATION #############################\n",
    "#######################################################\n",
    "n_s = 2  #number of sources to be estimated\n",
    "#Warning! if this one is 1, it's impossible build projection maps\n",
    "\n",
    "######## FastICA PARAMETERS \n",
    "whiten = 'arbitrary-variance'#True  ######## Maintain True\n",
    "fun    = 'logcosh' #exp,logcosh or\n",
    "max_iter = 20\n",
    "tol    = 0.01\n",
    "\n",
    "######## GMCA PARAMETERS   \n",
    "mints = 0.05 # min threshold (what is sparse compared to noise?)\n",
    "nmax  = 100 # number of iterations (usually 100 is safe)\n",
    "L0    = 0   # switch between L0 norm (1) or L1 norm (0)\n",
    "\n",
    "#######################################################\n",
    "AInit     = None\n",
    "ColFixed  = None\n",
    "whitening = False\n",
    "epsi      = 1e-3\n",
    "verbose   = False\n",
    "#GMCAExtension\n",
    "div          = 1 #  J+1  #J/div will should be even number\n",
    "without_covx = True # if your mixmatrix estimated will use covariance matrix of the observer data with ponderation\n",
    "# 0 <= noise factor <= 1\n",
    "#noise_factor = 1  <-------------- Preciso que os mapas sejam todos separados\n",
    "\n",
    "#######################################################\n",
    "################   DEBIAS PARAMETERS   ################\n",
    "#######################################################\n",
    "seed_used = 1     #If False, it will be chosen a random realization. Otherwise, it is necessary to write which realization that will be used. For example, if you want to use L10, it is necessary you to write 10 (it's string). Also, if you chose realizaton out of set, it will be chosen a random value.\n",
    "\n",
    "#######################################################\n",
    "################   PATHS PARAMETERS   #################\n",
    "#######################################################\n",
    "#path outputs\n",
    "pathout       = \"/home/amarins/CHISEL/outputs/NEWtest\" #Put here your path to the output cls\n",
    "cl_type_save  = \"reconstruction\" #You should choice between reconstruction or residuals cls values\n",
    "savefits      = True# or False\n",
    "#######################################################\n",
    "################   NAME FILES PARAMETERS   ############\n",
    "#######################################################\n",
    "# Name of FITS files inside of the pathmaps\n",
    "name_mask = 'mask_256_5degC2apod_20fgcut.fits' #put this file in the same directory of the other maps\n",
    "\n",
    "#Directory names\n",
    "dir_observed    = \"/media/BINGODATA1/ComponentSeparation/building_dataset/dataset_processed/OBSERVED\"\n",
    "dir_mask        = '/media/BINGODATA1/ComponentSeparation/building_dataset/dataset/M256'\n",
    "dir_prior       = \"/media/BINGODATA1/ComponentSeparation/building_dataset/dataset_processed/PRIOR\"\n",
    "dir_noise       = '/media/BINGODATA1/ComponentSeparation/building_dataset/dataset/WN256'\n",
    "dir_pure        = '/media/BINGODATA1/ComponentSeparation/building_dataset/dataset/HI256'\n",
    "dir_projprior   = \"/media/BINGODATA1/ComponentSeparation/building_dataset/dataset_processed/PRIOR\"\n",
    "dir_projnoise   = '/media/BINGODATA1/ComponentSeparation/building_dataset/dataset/WN256'\n",
    "dir_projpure    = '/media/BINGODATA1/ComponentSeparation/building_dataset/dataset/HI256'\n",
    "dir_foregrounds = '/media/BINGODATA1/ComsteerponentSeparation/building_dataset/dataset/FG256'\n",
    "\n",
    "#######################################################\n",
    "restart = True\n",
    "#if you were running the code and it broke, and you used \"n_realizations\" <total, the next run will assume restart = True, because it's impossible to know which nseed you used\n",
    "#warning: if you don't have the directories and put \"restart=False\" code wont be work. Please, put \"True\" to create directories and to run.\n",
    "#You cant cresteerate \"proj\" directories if you dont have all others directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96bc5ec-46cf-4b45-ac0e-e03038a964c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_maps = pd.Series({\"without_mean\":maps_wout_mean, \"apply_mask\":apply_mask, \"add_noise\":add_noise, \"cl_type_save\":cl_type_save})\n",
    "params_CS   = pd.Series({\"restart\":restart,\"n_realizations\":n_realizations, \"method\":method, \"first_realization\":first_realization,\n",
    "                         \"A_ini\":AInit, \"ColFixed\":ColFixed, \"whitening\":whitening, \"epsi\":epsi, \"verbose\":verbose, \"ns\":n_s, \"mints\":mints,\"nmax\":nmax, \"L0\":L0, \"division\":div, \"without_covx\":without_covx, \"seed_used\":seed_used,\n",
    "                         \"whiten\":whiten, \"fun\":fun, \"max_iter\":max_iter, \"tol\":tol})\n",
    "params_WT   = pd.Series({\"wtransform\":np.asarray(wtransform), \"use_c\":use_c, \"J\":J, \n",
    "                         \"L\":L, \"Jmin\":J_min, \"B\": B, \"N\":N, \"spin\":spin, \"upsample\":upsample,\n",
    "                         \"Jpwt\":Jpwt, \"pywttype\":pywttype.lower(),\n",
    "                         \"needlet\":needlet, \"Bneed\":Bneed, \"p\":p, \"fneed\": fneed, \"lmax_need\":lmax_need})\n",
    "params_path = pd.Series({\"pathout\":pathout, \"dir_observed\":dir_observed, \"dir_mask\":dir_mask, \"dir_noise\":dir_noise, \"dir_prior\":dir_prior,\"dir_pure\":dir_pure, \"dir_foregrounds\":dir_foregrounds, \"name_mask\":name_mask})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51f8d7ab-661b-4dfb-8c21-e430893723ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_seed_from_filenames(vectornames=None):\n",
    "    vectornames = np.asarray(vectornames)\n",
    "    ind = []\n",
    "    for n in vectornames:\n",
    "        ind.append(extracting_seed_from_string(n))\n",
    "    return np.asarray(ind)    \n",
    "def extracting_filename_from_seed(vectornames=None,vectorseeds=None,path=None):\n",
    "    import copy\n",
    "    nseed_0     = copy.deepcopy(vectorseeds)\n",
    "    if type(vectorseeds)==type(None): vectorseeds = extracting_seed_from_filenames(vectornames=vectornames)\n",
    "    index=[] \n",
    "    for i in range(len(nseed_0)):\n",
    "        n0 = nseed_0[i]\n",
    "        index.append(np.where(vectorseeds==n0)[0][0])\n",
    "    index  = np.asarray(index) \n",
    "    return vectornames[index], vectorseeds[index]\n",
    "\n",
    "\n",
    "def nsamples(params_CS=None,params_path=None, path=None, listdir=\"21cm\", nseed_used=False):\n",
    "    try:\n",
    "        cs.checkwrongfile(pathout=params_path.pathout, file=\".ipynb_checkpoints\")\n",
    "    except:\n",
    "        pass\n",
    "    names_0  = np.asarray(os.listdir(path))\n",
    "    nfiles   = names_0.size\n",
    "    if nfiles>=params_CS['n_realizations']:\n",
    "        if listdir in [\"21cm\",\"foregrounds\",\"mixmatrix\"]:\n",
    "            #it will work \n",
    "            if params_CS['restart'] or (params_CS['n_realizations']<nfiles):\n",
    "                if int(params_CS.seed_used)==params_CS['first_realization']: \n",
    "                    notdone = np.arange(params_CS['first_realization']+1,params_CS['first_realization']+nfiles)\n",
    "                elif int(params_CS.seed_used)==int(params_CS['first_realization']+nfiles-1):\n",
    "                    notdone = np.arange(params_CS['first_realization'], params_CS['first_realization']+nfiles-1-1)\n",
    "                else:\n",
    "                    notdone = np.hstack((np.arange(params_CS['first_realization'],params_CS.seed_used),np.arange(params_CS.seed_used+1,params_CS['first_realization']+nfiles)))\n",
    "                nseed_0 = np.hstack((np.array([params_CS.seed_used]),notdone))\n",
    "                print(notdone)\n",
    "                nseed_0 = nseed_0[:params_CS['n_realizations']]\n",
    "                names_0 = extracting_filename_from_seed(vectornames=names_0, vectorseeds=nseed_0, path=path)[0]\n",
    "    ########################################################################################################################                \n",
    "            else:#caso em que sao usado tds realizacoes e nao eh para reiniciar, sera verificado quais arquivos ha e selecionar os que nao ha\n",
    "                nseed_0 = cs.extracting_seed_from_filenames(vectornames=names_0)\n",
    "                done    = []\n",
    "                for ipath in os.listdir(os.path.join(params_path.pathout,listdir)):\n",
    "                    done.append(int(ipath.split(\"_\")[1].split(\".\")[0].split(\"L\")[1]))\n",
    "                done    = np.sort(np.asarray(done))\n",
    "                notdone = np.setdiff1d(nseed_0,done)    \n",
    "                names_0 = extracting_filename_from_seed(vectornames=names_0, vectorseeds=notdone, path=path)[0]\n",
    "                nseed_0 = cs.extracting_seed_from_filenames(vectornames=names_0)\n",
    "            return names_0, nseed_0\n",
    "    ########################################################################################################################         \n",
    "        elif listdir in [\"prior\",\"pure\",\"noise\",\"projprior\",\"projpure\",\"projnoise\"]:\n",
    "            done = []\n",
    "            for ipath in os.listdir(os.path.join(params_path.pathout,listdir)):\n",
    "                done.append(int(ipath.split(\"_\")[1].split(\".\")[0].split(\"L\")[1]))\n",
    "            done    = np.sort(np.asarray(done))\n",
    "            notdone = np.setdiff1d(nseed_used, done)  \n",
    "            names_0 = extracting_filename_from_seed(vectornames=names_0, vectorseeds=notdone, path=path)[0]\n",
    "            nseed_0 = cs.extracting_seed_from_filenames(vectornames=names_0)\n",
    "            #names, nseed  = extracting_filename_from_seed(vectornames=names, vectorseeds=nseed_used, path=params_path.dir_noise)\n",
    "            return names_0, nseed_0\n",
    "\n",
    "        else:\n",
    "            raise NameError(\"It was not found {}\".format(listdir))\n",
    "    else:\n",
    "        raise NameError(\"{} > number of realizations (= {}) \".format(params_CS['n_realizations'], nfiles)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f892c093-ad5d-4ec9-8fec-fc0f51be51ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_maps[\"getdata\"] = \"noise\"\n",
    "subdirs                = [\"noise\"]\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5765d19-16b9-4098-8436-ad2159ebc253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([34]), 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params_maps[\"getdata\"] = \"noise\"\n",
    "params_CS['n_realizations'] = 100\n",
    "params_CS['seed_used'] = 3\n",
    "params_CS['first_realization'] = 1\n",
    "params_CS['restart']=False#first_realization there is no action here\n",
    "names0, nseed0 = nsamples(params_CS,params_path,path=params_path.dir_observed, listdir=\"noise\")\n",
    "nseed0, nseed0.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d1db0-e121-483e-adf1-d716a322dd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
